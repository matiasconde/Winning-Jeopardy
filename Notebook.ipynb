{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import chisquare, chi2_contingency\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Show Number    Air Date      Round                         Category  Value  \\\n",
      "0         4680  2004-12-31  Jeopardy!                          HISTORY   $200   \n",
      "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
      "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   $200   \n",
      "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE   $200   \n",
      "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   $200   \n",
      "\n",
      "                                            Question      Answer  \n",
      "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
      "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
      "2  The city of Yuma in this state has a record av...     Arizona  \n",
      "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
      "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  \n",
      "Index(['Show Number', ' Air Date', ' Round', ' Category', ' Value',\n",
      "       ' Question', ' Answer'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "jeopardy = pd.read_csv(\"jeopardy.csv\")\n",
    "print(jeopardy.head())\n",
    "print(jeopardy.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeopardy.columns = ['Show Number', 'Air Date', 'Round', 'Category', 'Value',\n",
    "       'Question', 'Answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    for the last 8 years of his life galileo was u...\n",
      "1    no 2 1912 olympian football star at carlisle i...\n",
      "2    the city of yuma in this state has a record av...\n",
      "3    in 1963 live on the art linkletter show this c...\n",
      "4    signer of the dec of indep framer of the const...\n",
      "Name: clean_question, dtype: object\n",
      "0    copernicus\n",
      "1    jim thorpe\n",
      "2       arizona\n",
      "3     mcdonalds\n",
      "4    john adams\n",
      "Name: clean_answer, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def normalize(s):\n",
    "    s = s.lower()\n",
    "    for punct in string.punctuation:\n",
    "        s = s.replace(punct,\"\")\n",
    "    return s\n",
    "\n",
    "jeopardy[\"clean_question\"] = jeopardy[\"Question\"].apply(normalize)\n",
    "jeopardy[\"clean_answer\"] = jeopardy[\"Answer\"].astype(str,copy=False).apply(normalize)\n",
    "print(jeopardy[\"clean_question\"].head())\n",
    "print(jeopardy[\"clean_answer\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dollar(s):\n",
    "    s=s.replace(\"$\",\"\")\n",
    "    s=s.replace(\",\",\".\")\n",
    "    if s==\"None\":\n",
    "        return 0\n",
    "    return float(s)\n",
    "\n",
    "jeopardy[\"clean_value\"] = jeopardy[\"Value\"].apply(normalize_dollar)\n",
    "jeopardy[\"Air Date\"] = pd.to_datetime(jeopardy[\"Air Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     200.0\n",
       "1     200.0\n",
       "2     200.0\n",
       "3     200.0\n",
       "4     200.0\n",
       "5     200.0\n",
       "6     400.0\n",
       "7     400.0\n",
       "8     400.0\n",
       "9     400.0\n",
       "10    400.0\n",
       "11    400.0\n",
       "12    600.0\n",
       "13    600.0\n",
       "14    600.0\n",
       "15    600.0\n",
       "16    600.0\n",
       "17    600.0\n",
       "18    800.0\n",
       "19    800.0\n",
       "20    800.0\n",
       "Name: clean_value, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy[\"clean_value\"].head(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_answer_in_question(row_jeopardy):\n",
    "# takes an answer, then divides it into words and finally verifies\n",
    "# the proportion of words in the answer also present in his\n",
    "# corresponding question\n",
    "   \n",
    "    split_answer = row_jeopardy[\"clean_answer\"].split(\" \")\n",
    "    split_question = row_jeopardy[\"clean_question\"].split(\" \")\n",
    "    \n",
    "    match_count = 0\n",
    "    if \"the\" in split_answer:\n",
    "        split_answer.remove(\"the\")\n",
    "    if len(split_answer)==0: return 0\n",
    "    for answer in split_answer:\n",
    "        if answer in split_question:\n",
    "            match_count += 1\n",
    "    return match_count / len(split_answer)\n",
    "\n",
    "jeopardy[\"answer_in_question\"] = jeopardy.apply(prob_answer_in_question,axis=1)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.060352773854699004"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy[\"answer_in_question\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  First analysis\n",
    "The function created for the analysis takes each row of the data set \"hazard\" and count how many words of the answer appear in his question. then this amount is divided by the number of words in the answer:\n",
    "- This will tell us row by row what percentage of the answer appears in the question, 100% is that all the words of the answer appear in his question, 33.333% that only 1 of the three words of the answer appears in his question, etc. .\n",
    "\n",
    "Taking the average of all these values ​​generates a value that we can use to estimate the typical percentage of words in the answers that appear in his question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6871242880966756"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_overlap = []\n",
    "terms_used = set()\n",
    "jeopardy.sort_values(by=\"Air Date\", inplace=True)\n",
    "\n",
    "for i,row in jeopardy.iterrows():\n",
    "    match_count = 0\n",
    "    split_question = row[\"clean_question\"].split(\" \")\n",
    "    split_question = [q for q in split_question if len(q) > 5]\n",
    "    for word in split_question:\n",
    "        if word in terms_used:\n",
    "            match_count += 1\n",
    "    for word in split_question:\n",
    "        terms_used.add(word)\n",
    "    if len(split_question)>0:\n",
    "        question_overlap.append(match_count / len(split_question))\n",
    "    else: question_overlap.append(0)\n",
    "\n",
    "jeopardy[\"question_overlap\"] = question_overlap\n",
    "jeopardy[\"question_overlap\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Conclusions: There is almost a 70% of isolated words that appears in old questions (for old questions we understand questions that occurred at most the immediate previous date). This value doesn't mean much since there are isolated words and not complete phrases . We need to investigate further.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def over_800USD(row):\n",
    "    if float(row[\"clean_value\"])>800:\n",
    "        value=1\n",
    "    else: value=0\n",
    "    return value\n",
    "\n",
    "jeopardy[\"high_value\"] = jeopardy.apply(over_800USD,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(word):\n",
    "    low_count=0\n",
    "    high_count=0\n",
    "    for i,row in jeopardy.iterrows():\n",
    "        split_question = row[\"clean_question\"].split(\" \")\n",
    "        if word in split_question:\n",
    "            if row[\"high_value\"]==1:\n",
    "                high_count += 1\n",
    "            else: low_count += 1\n",
    "    return high_count, low_count\n",
    "\n",
    "observed_expected = []\n",
    "\n",
    "comparison_terms = list(terms_used)[:25]\n",
    "\n",
    "for term in comparison_terms:\n",
    "    result = count_words(term)\n",
    "    observed_expected.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 3),\n",
       " (1, 1),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (1, 3),\n",
       " (1, 0),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (1, 1),\n",
       " (0, 3),\n",
       " (0, 1),\n",
       " (0, 2),\n",
       " (0, 1),\n",
       " (0, 2),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (1, 0),\n",
       " (4, 2),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (2, 2)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_value_count = jeopardy[jeopardy[\"high_value\"]==1][\"high_value\"].count()\n",
    "low_value_count = jeopardy[jeopardy[\"high_value\"]==0][\"high_value\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.9926132960670793, 0.31910449982424866), (0.6765980594008285, 0.4107606373026975), (0.3308710986890265, 0.565146603267378), (0.3308710986890265, 0.565146603267378), (4.122707846712507e-05, 0.9948769527982859), (3.022325020112631, 0.08212564786568953), (0.3308710986890265, 0.565146603267378), (0.3308710986890265, 0.565146603267378), (0.3308710986890265, 0.565146603267378), (0.6765980594008285, 0.4107606373026975), (0.9926132960670793, 0.31910449982424866), (0.3308710986890265, 0.565146603267378), (0.661742197378053, 0.4159455550913673), (0.3308710986890265, 0.565146603267378), (0.661742197378053, 0.4159455550913673), (0.3308710986890265, 0.565146603267378), (0.3308710986890265, 0.565146603267378), (0.3308710986890265, 0.565146603267378), (3.022325020112631, 0.08212564786568953), (5.6134474527597, 0.017823164380903502), (3.022325020112631, 0.08212564786568953), (0.6765980594008285, 0.4107606373026975), (0.3308710986890265, 0.565146603267378), (0.3308710986890265, 0.565146603267378), (1.353196118801657, 0.2447201432712674)]\n"
     ]
    }
   ],
   "source": [
    "chi_squared = []\n",
    "for each in observed_expected:\n",
    "    total = each[0]+each[1]\n",
    "    total_prop = total/jeopardy.shape[0]\n",
    "    expected_high_value_counts = total_prop*high_value_count\n",
    "    expected_low_value_counts = total_prop*low_value_count\n",
    "    expected = np.array([expected_high_value_counts,expected_low_value_counts])\n",
    "    observed = np.array([each[0],each[1]])\n",
    "    chisquare_value, pvalue = chisquare(observed, expected)\n",
    "    chi_squared.append((chisquare_value,pvalue))\n",
    "\n",
    "print(chi_squared)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chis_squared_promediate:  1.0137047283335516\n",
      "pvalues_promediate:  0.43951753859981535\n"
     ]
    }
   ],
   "source": [
    "chis, pval = 0, 0\n",
    "\n",
    "for each in chi_squared:\n",
    "    chis += each[0]\n",
    "    pval += each[1]\n",
    "\n",
    "chis_squared_promediate = chis/len(chi_squared)\n",
    "pvalues_promediate = pval/len(chi_squared)\n",
    "\n",
    "print(\"chis_squared_promediate: \",chis_squared_promediate)\n",
    "print(\"pvalues_promediate: \",pvalues_promediate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observing p-values and chi-squared values:\n",
    "\n",
    "- Generlly we haven't low p-values indicating that the chi-squared value obtained  of the categorical distribution of words present in low and high USD values questions is not very rare. \n",
    "Then there is high probability of get this distribution by chance. Hence There isn't a Statistical significance in data for the study of \"high-low USD-value words\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some further analytis:\n",
    "- Increasing the list of english stopwords to remove from questions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
    "stopwords2 = ['a', 'about', 'above', 'after',\n",
    " 'again', 'against', 'all', 'am', 'an', 'and', 'any', 'are', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', \"can't\", 'cannot', 'could', \"couldn't\", 'did', \"didn't\", 'do', 'does', \"doesn't\", 'doing', \"don't\", 'down', 'during', 'each', 'few', 'for',\n",
    " 'from', 'further', 'had', \"hadn't\", 'has', \"hasn't\", 'have', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", \"he's\", 'her', 'here', \"here's\", 'hers', 'herself', 'him', 'himself', 'his', 'how', \"how's\", 'i', \"i'd\", \"i'll\", \"i'm\", \"i've\",'if', 'in', 'into', 'is', \"isn't\", 'it', \"it's\", 'its', 'itself', \"let's\", 'me', 'more', 'most', \"mustn't\", 'my', 'myself', 'no', 'nor', 'not', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'ought', 'our', 'ours\\tourselves', 'out', 'over', 'own', 'same', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', \"shouldn't\", 'so', 'some', 'such', 'than', 'that', \"that's\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', \"there's\", 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 'very', 'was', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", \"we've\", 'were', \"weren't\", 'what', \"what's\", 'when', \"when's\", 'where', \"where's\", 'which', 'while', 'who', \"who's\", 'whom', 'why', \"why's\", 'with', \n",
    "              \"won't\", 'would', \"wouldn't\", 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours','yourself','yourselves']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_overlap2</th>\n",
       "      <th>Air Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19325</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19324</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19301</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19302</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19303</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19304</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19305</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19306</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19308</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19309</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19310</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19311</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19307</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19313</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19322</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19321</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19320</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19319</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19318</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19323</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19316</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       question_overlap2   Air Date\n",
       "19325           0.000000 1984-09-21\n",
       "19324           0.000000 1984-09-21\n",
       "19301           0.000000 1984-09-21\n",
       "19302           0.000000 1984-09-21\n",
       "19303           0.250000 1984-09-21\n",
       "19304           0.000000 1984-09-21\n",
       "19305           0.000000 1984-09-21\n",
       "19306           0.000000 1984-09-21\n",
       "19308           0.000000 1984-09-21\n",
       "19309           0.000000 1984-09-21\n",
       "19310           0.000000 1984-09-21\n",
       "19311           0.000000 1984-09-21\n",
       "19307           0.000000 1984-09-21\n",
       "19313           0.000000 1984-09-21\n",
       "19322           0.000000 1984-09-21\n",
       "19321           0.125000 1984-09-21\n",
       "19320           0.100000 1984-09-21\n",
       "19319           0.100000 1984-09-21\n",
       "19318           0.000000 1984-09-21\n",
       "19323           0.000000 1984-09-21\n",
       "19316           0.166667 1984-09-21"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_overlap2 = []\n",
    "terms_used2 = set()\n",
    "jeopardy.sort_values(by=\"Air Date\", inplace=True)\n",
    "\n",
    "for i,row in jeopardy.iterrows():\n",
    "    match_count = 0\n",
    "    split_question = row[\"clean_question\"].split(\" \")\n",
    "    split_question = [q for q in split_question if (q not in stopwords2)] # and (len(q)>5)]\n",
    "    for word in split_question:\n",
    "        if word in terms_used2:\n",
    "            match_count += 1\n",
    "    for word in split_question:\n",
    "        terms_used2.add(word)\n",
    "    if len(split_question)>0:\n",
    "        question_overlap2.append(match_count / len(split_question))\n",
    "    else: question_overlap2.append(0)\n",
    "\n",
    "jeopardy[\"question_overlap2\"] = question_overlap2\n",
    "jeopardy[[\"question_overlap2\",\"Air Date\"]].head(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7968490723431718"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy[\"question_overlap2\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### New results: 79% of the words used in old questions appears on new ones. This time we do the cut with english stopwords rather than words with lenght < 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let´s go to obtain the frequency-value-words-appear more efficient using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24532"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(terms_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19999, 14)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17859\n"
     ]
    }
   ],
   "source": [
    "terms_used_list = []\n",
    "for word in terms_used:\n",
    "    if len(word)<10:\n",
    "        terms_used_list.append(word)\n",
    "print(len(terms_used_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8419</th>\n",
       "      <td>xstatic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17076</th>\n",
       "      <td>hatter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11206</th>\n",
       "      <td>starkists</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5741</th>\n",
       "      <td>herbert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10154</th>\n",
       "      <td>pensee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>recover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2217</th>\n",
       "      <td>regulates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17064</th>\n",
       "      <td>inflate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13635</th>\n",
       "      <td>marple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15040</th>\n",
       "      <td>assures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15482</th>\n",
       "      <td>fireproof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14472</th>\n",
       "      <td>existence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8696</th>\n",
       "      <td>cheerful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15043</th>\n",
       "      <td>blossoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6696</th>\n",
       "      <td>upside</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13424</th>\n",
       "      <td>withstand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16546</th>\n",
       "      <td>commands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14277</th>\n",
       "      <td>marjorie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9535</th>\n",
       "      <td>toubkal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4780</th>\n",
       "      <td>gardens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11306</th>\n",
       "      <td>locklear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3896</th>\n",
       "      <td>choctaw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15437</th>\n",
       "      <td>tinder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15354</th>\n",
       "      <td>ebullient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>selfpity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5101</th>\n",
       "      <td>bluefrom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11941</th>\n",
       "      <td>resulting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14941</th>\n",
       "      <td>barrie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10995</th>\n",
       "      <td>missile</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word\n",
       "8419     xstatic\n",
       "416     notebook\n",
       "17076     hatter\n",
       "11206  starkists\n",
       "5741     herbert\n",
       "10154     pensee\n",
       "619      recover\n",
       "2217   regulates\n",
       "17064    inflate\n",
       "13635     marple\n",
       "15040    assures\n",
       "15482  fireproof\n",
       "14472  existence\n",
       "8696    cheerful\n",
       "15043   blossoms\n",
       "6696      upside\n",
       "13424  withstand\n",
       "16546   commands\n",
       "14277   marjorie\n",
       "9535     toubkal\n",
       "4780     gardens\n",
       "11306   locklear\n",
       "3896     choctaw\n",
       "15437     tinder\n",
       "15354  ebullient\n",
       "746     selfpity\n",
       "5101    bluefrom\n",
       "11941  resulting\n",
       "14941     barrie\n",
       "10995    missile"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms_used_df = pd.DataFrame(terms_used_list,columns=[\"word\"]).sample(n=60)\n",
    "terms_used_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words2(word):\n",
    "    low_count=0\n",
    "    high_count=0\n",
    "    for i,row in jeopardy.iterrows():\n",
    "        split_question = row[\"clean_question\"].split(\" \")\n",
    "        if word in split_question:\n",
    "            if row[\"high_value\"]==1:\n",
    "                high_count += 1\n",
    "            else: low_count += 1\n",
    "    return high_count, low_count, word\n",
    "\n",
    "terms_used_df[\"high-low value-word\"] = terms_used_df[\"word\"].apply(count_words2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>high-low value-word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8419</th>\n",
       "      <td>xstatic</td>\n",
       "      <td>(0, 1, xstatic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>notebook</td>\n",
       "      <td>(0, 2, notebook)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17076</th>\n",
       "      <td>hatter</td>\n",
       "      <td>(0, 2, hatter)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11206</th>\n",
       "      <td>starkists</td>\n",
       "      <td>(0, 1, starkists)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5741</th>\n",
       "      <td>herbert</td>\n",
       "      <td>(0, 12, herbert)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10154</th>\n",
       "      <td>pensee</td>\n",
       "      <td>(0, 1, pensee)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>recover</td>\n",
       "      <td>(1, 2, recover)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2217</th>\n",
       "      <td>regulates</td>\n",
       "      <td>(1, 1, regulates)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17064</th>\n",
       "      <td>inflate</td>\n",
       "      <td>(1, 1, inflate)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13635</th>\n",
       "      <td>marple</td>\n",
       "      <td>(0, 2, marple)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15040</th>\n",
       "      <td>assures</td>\n",
       "      <td>(1, 0, assures)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15482</th>\n",
       "      <td>fireproof</td>\n",
       "      <td>(1, 1, fireproof)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14472</th>\n",
       "      <td>existence</td>\n",
       "      <td>(1, 2, existence)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8696</th>\n",
       "      <td>cheerful</td>\n",
       "      <td>(1, 0, cheerful)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15043</th>\n",
       "      <td>blossoms</td>\n",
       "      <td>(0, 2, blossoms)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6696</th>\n",
       "      <td>upside</td>\n",
       "      <td>(2, 1, upside)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13424</th>\n",
       "      <td>withstand</td>\n",
       "      <td>(1, 0, withstand)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16546</th>\n",
       "      <td>commands</td>\n",
       "      <td>(0, 1, commands)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14277</th>\n",
       "      <td>marjorie</td>\n",
       "      <td>(1, 1, marjorie)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9535</th>\n",
       "      <td>toubkal</td>\n",
       "      <td>(0, 1, toubkal)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4780</th>\n",
       "      <td>gardens</td>\n",
       "      <td>(2, 8, gardens)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11306</th>\n",
       "      <td>locklear</td>\n",
       "      <td>(0, 1, locklear)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3896</th>\n",
       "      <td>choctaw</td>\n",
       "      <td>(1, 1, choctaw)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15437</th>\n",
       "      <td>tinder</td>\n",
       "      <td>(0, 1, tinder)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15354</th>\n",
       "      <td>ebullient</td>\n",
       "      <td>(0, 1, ebullient)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>selfpity</td>\n",
       "      <td>(0, 1, selfpity)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5101</th>\n",
       "      <td>bluefrom</td>\n",
       "      <td>(0, 1, bluefrom)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11941</th>\n",
       "      <td>resulting</td>\n",
       "      <td>(0, 1, resulting)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14941</th>\n",
       "      <td>barrie</td>\n",
       "      <td>(0, 4, barrie)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10995</th>\n",
       "      <td>missile</td>\n",
       "      <td>(0, 6, missile)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word high-low value-word\n",
       "8419     xstatic     (0, 1, xstatic)\n",
       "416     notebook    (0, 2, notebook)\n",
       "17076     hatter      (0, 2, hatter)\n",
       "11206  starkists   (0, 1, starkists)\n",
       "5741     herbert    (0, 12, herbert)\n",
       "10154     pensee      (0, 1, pensee)\n",
       "619      recover     (1, 2, recover)\n",
       "2217   regulates   (1, 1, regulates)\n",
       "17064    inflate     (1, 1, inflate)\n",
       "13635     marple      (0, 2, marple)\n",
       "15040    assures     (1, 0, assures)\n",
       "15482  fireproof   (1, 1, fireproof)\n",
       "14472  existence   (1, 2, existence)\n",
       "8696    cheerful    (1, 0, cheerful)\n",
       "15043   blossoms    (0, 2, blossoms)\n",
       "6696      upside      (2, 1, upside)\n",
       "13424  withstand   (1, 0, withstand)\n",
       "16546   commands    (0, 1, commands)\n",
       "14277   marjorie    (1, 1, marjorie)\n",
       "9535     toubkal     (0, 1, toubkal)\n",
       "4780     gardens     (2, 8, gardens)\n",
       "11306   locklear    (0, 1, locklear)\n",
       "3896     choctaw     (1, 1, choctaw)\n",
       "15437     tinder      (0, 1, tinder)\n",
       "15354  ebullient   (0, 1, ebullient)\n",
       "746     selfpity    (0, 1, selfpity)\n",
       "5101    bluefrom    (0, 1, bluefrom)\n",
       "11941  resulting   (0, 1, resulting)\n",
       "14941     barrie      (0, 4, barrie)\n",
       "10995    missile     (0, 6, missile)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms_used_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4972 15027\n"
     ]
    }
   ],
   "source": [
    "high_value_count2 = jeopardy[jeopardy[\"high_value\"]==1][\"high_value\"].count()\n",
    "low_value_count2 = jeopardy[jeopardy[\"high_value\"]==0][\"high_value\"].count()\n",
    "print(high_value_count2,low_value_count2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.3308710986890265, 0.565146603267378, 'xstatic'), (0.661742197378053, 0.4159455550913673, 'notebook'), (0.661742197378053, 0.4159455550913673, 'hatter'), (0.3308710986890265, 0.565146603267378, 'starkists'), (3.970453184268317, 0.046305308527765786, 'herbert'), (0.3308710986890265, 0.565146603267378, 'pensee'), (0.11526980495624546, 0.7342224981885828, 'recover'), (0.6765980594008285, 0.4107606373026975, 'regulates'), (0.6765980594008285, 0.4107606373026975, 'inflate'), (0.661742197378053, 0.4159455550913673, 'marple'), (3.022325020112631, 0.08212564786568953, 'assures'), (0.6765980594008285, 0.4107606373026975, 'fireproof'), (0.11526980495624546, 0.7342224981885828, 'existence'), (3.022325020112631, 0.08212564786568953, 'cheerful'), (0.661742197378053, 0.4159455550913673, 'blossoms'), (2.80672372637985, 0.09386990525628017, 'upside'), (3.022325020112631, 0.08212564786568953, 'withstand'), (0.3308710986890265, 0.565146603267378, 'commands'), (0.6765980594008285, 0.4107606373026975, 'marjorie'), (0.3308710986890265, 0.565146603267378, 'toubkal'), (0.12650503965482127, 0.7220836177367724, 'gardens'), (0.3308710986890265, 0.565146603267378, 'locklear'), (0.6765980594008285, 0.4107606373026975, 'choctaw'), (0.3308710986890265, 0.565146603267378, 'tinder'), (0.3308710986890265, 0.565146603267378, 'ebullient'), (0.3308710986890265, 0.565146603267378, 'selfpity'), (0.3308710986890265, 0.565146603267378, 'bluefrom'), (0.3308710986890265, 0.565146603267378, 'resulting'), (1.323484394756106, 0.2499676669229765, 'barrie'), (1.9852265921341585, 0.1588408772825072, 'missile')]\n"
     ]
    }
   ],
   "source": [
    "def chi_squared_df(term):\n",
    "    \n",
    "    total = term[0]+term[1]\n",
    "    total_prop = total/jeopardy.shape[0]\n",
    "    expected_high_value_counts = total_prop*high_value_count\n",
    "    expected_low_value_counts = total_prop*low_value_count\n",
    "    expected = np.array([expected_high_value_counts,expected_low_value_counts])\n",
    "    observed = np.array([term[0],term[1]])\n",
    "    chisquare_value, pvalue = chisquare(observed, expected)\n",
    "    chi_squared = (chisquare_value,pvalue,term[2])\n",
    "    return chi_squared\n",
    "\n",
    "chi_squared = terms_used_df[\"high-low value-word\"].apply(chi_squared_df)\n",
    "print(chi_squared.tolist()[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "herbert\n",
      "assures\n",
      "cheerful\n",
      "upside\n",
      "withstand\n",
      "wilshire\n",
      "hurston\n",
      "titled\n",
      "harlan\n",
      "orators\n",
      "metalcore\n",
      "8419                  None\n",
      "416                   None\n",
      "17076                 None\n",
      "11206                 None\n",
      "5741      (0, 12, herbert)\n",
      "10154                 None\n",
      "619                   None\n",
      "2217                  None\n",
      "17064                 None\n",
      "13635                 None\n",
      "15040      (1, 0, assures)\n",
      "15482                 None\n",
      "14472                 None\n",
      "8696      (1, 0, cheerful)\n",
      "15043                 None\n",
      "6696        (2, 1, upside)\n",
      "13424    (1, 0, withstand)\n",
      "16546                 None\n",
      "14277                 None\n",
      "9535                  None\n",
      "4780                  None\n",
      "11306                 None\n",
      "3896                  None\n",
      "15437                 None\n",
      "15354                 None\n",
      "746                   None\n",
      "5101                  None\n",
      "11941                 None\n",
      "14941                 None\n",
      "10995                 None\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "list_of_words = []\n",
    "for each in chi_squared.tolist():\n",
    "    \n",
    "    if each[1]<0.1:\n",
    "        word_significant = each[2]\n",
    "        print(word_significant)\n",
    "        list_of_words.append(word_significant)\n",
    "\n",
    "        \n",
    "def determining_low_pvalues(df):\n",
    "    \n",
    "    word = df[\"word\"]\n",
    "    if word in list_of_words:\n",
    "        return df[\"high-low value-word\"]\n",
    "\n",
    "print(terms_used_df.apply(determining_low_pvalues,axis=1).head(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### the chi-squared test shows than only a few words in a sample of 60 have statistical significance. The words are:\n",
    "- sparta\n",
    "- alfalfa\n",
    "- santini\n",
    "- denied\n",
    "- honcho\n",
    "- numeral\n",
    "- backcourt\n",
    "- dollpuss\n",
    "- tuxedos\n",
    "- strapped\n",
    "- predating\n",
    "\n",
    "All these words have appearances on high value questions (over 800 USD), the first one in the amount of appearances is \"sparta\" with 2.\n",
    "\n",
    "The numbers are not very high but we must to consider that we have only used a sample of n = 60 terms used in questions selected ramdomly. If we make a gross and possibly incorrect extrapolation, but only for the purpose of generating some ideas, 2 in 60 are the 3.33% and the whole set of terms used in older questions are approximatelly 17859 words, then the 3.33% of this number is 594 an insteresting amount of times that \"sparta\" appears on high-value questions from a total of 20,000 questions colected in the dataset.\n",
    "\n",
    "##### The next steps in all this complex analysis are the taking of a most bigger data-set (on external workplaces like google colab I have taked a data-set of 200,000 rows, the percentages of words used in older questions goes up as well as others but in these cases we need a most powerfull way to do computations).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Some last analysis: counting phrases overlaping on older questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_overlap3</th>\n",
       "      <th>Air Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19325</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19285</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19324</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19301</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19302</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19303</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19304</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19305</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19308</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19309</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19310</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19311</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19306</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19313</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19314</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19315</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19316</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19323</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19318</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19317</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19320</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19321</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19322</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19319</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19300</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19286</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19307</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19297</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19312</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19299</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1984-09-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       question_overlap3   Air Date\n",
       "19325                0.0 1984-09-21\n",
       "19285                0.0 1984-09-21\n",
       "19324                0.0 1984-09-21\n",
       "19301                0.0 1984-09-21\n",
       "19302                0.0 1984-09-21\n",
       "19303                0.0 1984-09-21\n",
       "19304                0.0 1984-09-21\n",
       "19305                0.0 1984-09-21\n",
       "19308                0.0 1984-09-21\n",
       "19309                0.0 1984-09-21\n",
       "19310                0.0 1984-09-21\n",
       "19311                0.0 1984-09-21\n",
       "19306                0.0 1984-09-21\n",
       "19313                0.0 1984-09-21\n",
       "19314                0.0 1984-09-21\n",
       "19315                0.0 1984-09-21\n",
       "19316                0.0 1984-09-21\n",
       "19323                0.0 1984-09-21\n",
       "19318                0.0 1984-09-21\n",
       "19317                0.0 1984-09-21\n",
       "19320                0.0 1984-09-21\n",
       "19321                0.0 1984-09-21\n",
       "19322                0.0 1984-09-21\n",
       "19319                0.0 1984-09-21\n",
       "19300                0.0 1984-09-21\n",
       "19286                0.0 1984-09-21\n",
       "19307                0.0 1984-09-21\n",
       "19297                0.0 1984-09-21\n",
       "19312                0.0 1984-09-21\n",
       "19299                0.0 1984-09-21"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_overlap3 = []\n",
    "phrases_used = set()\n",
    "jeopardy.sort_values(by=\"Air Date\", inplace=True)\n",
    "\n",
    "for i,row in jeopardy.iterrows():\n",
    "    match_count = 0\n",
    "    split_question = row[\"clean_question\"].split(\",\")\n",
    "    split_question = [q for q in split_question if (q not in stopwords2)] # and (len(q)>5)]\n",
    "    for phrase in split_question:\n",
    "        if phrase in phrases_used:\n",
    "            match_count += 1\n",
    "    for phrase in split_question:\n",
    "        phrases_used.add(phrase)\n",
    "    if len(split_question)>0:\n",
    "        question_overlap3.append(match_count / len(split_question))\n",
    "    else: question_overlap3.append(0)\n",
    "\n",
    "jeopardy[\"question_overlap3\"] = question_overlap3\n",
    "jeopardy[[\"question_overlap3\",\"Air Date\"]].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000600030001500075"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy[\"question_overlap3\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The percentage are very very low, this can indicate that phrases have high varations over time. This doesn't mean that the subject of the questions has the same variations. Jeopardy can make small variances on questions to generate some aparent variability without varyng their instrinsict subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TELEVISION              51\n",
       "U.S. GEOGRAPHY          50\n",
       "LITERATURE              45\n",
       "HISTORY                 40\n",
       "AMERICAN HISTORY        40\n",
       "BEFORE & AFTER          40\n",
       "AUTHORS                 39\n",
       "WORD ORIGINS            38\n",
       "WORLD CAPITALS          37\n",
       "BODIES OF WATER         36\n",
       "SPORTS                  36\n",
       "SCIENCE & NATURE        35\n",
       "RHYME TIME              35\n",
       "SCIENCE                 35\n",
       "MAGAZINES               35\n",
       "WORLD GEOGRAPHY         33\n",
       "HISTORIC NAMES          32\n",
       "WORLD HISTORY           32\n",
       "ANNUAL EVENTS           32\n",
       "IN THE DICTIONARY       31\n",
       "BIRDS                   31\n",
       "FICTIONAL CHARACTERS    31\n",
       "U.S. PRESIDENTS         30\n",
       "ISLANDS                 30\n",
       "OPERA                   30\n",
       "TRAVEL & TOURISM        30\n",
       "MEDICINE                30\n",
       "POTPOURRI               30\n",
       "BALLET                  29\n",
       "ART                     28\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy[\"Category\"].value_counts().head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Looking the rankings in \"Categories\":\n",
    "- TELEVISION                        51\n",
    "- U.S. GEOGRAPHY                    50\n",
    "- LITERATURE                        45\n",
    "- BEFORE & AFTER                    40\n",
    "- AMERICAN HISTORY                  40\n",
    "- HISTORY                           40\n",
    "- AUTHORS                           39\n",
    "- WORD ORIGINS                      38\n",
    "- WORLD CAPITALS                    37\n",
    "- SPORTS                            36\n",
    "- BODIES OF WATER                   36\n",
    "- RHYME TIME                        35\n",
    "- SCIENCE                           35\n",
    "\n",
    "Based on this ranking of categories, we can surmise that the questions with the greatest variability fall on the categories most frequently ocurred. So, in order to have more chances of winning Jeopardy, the participant needs to have a vast knowledge in the top 5 categories, and a general culture for the rest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
